AWSTemplateFormatVersion: "2010-09-09"
Description: "Create an S3 Bucket"

Resources:

    MyS3Bucket:
        Type: AWS::S3::Bucket
        DeletionPolicy: Delete
        Properties:
            BucketName: mergeddatar15

    Mybucket:
        Type: AWS::S3::Bucket
        DependsOn: LambdaInvokePermission
        Properties:
            BucketName: scriptfile1
            NotificationConfiguration:
                LambdaConfigurations:
                    - Event: 's3:ObjectCreated:*'
                      Function: !GetAtt WorkflowLambda.Arn
            


    GlueDatabase:
        Type: AWS::Glue::Database
        Properties:
            CatalogId: !Ref AWS::AccountId
            DatabaseInput:
                Name: database65  
                   

    WorkflowJob:
        Type: AWS::Glue::Workflow
        Properties:
            Description: Create workflow
            MaxConcurrentRuns: 1
            Name: jobworkflow1        
    
    GlueJobImport:
        Type: AWS::Glue::Job
        DependsOn: MyS3Bucket
        Properties:
            Name: data-importsep39
            Description: Ingests data from s3 and writes it as a parquet file to the data lake
            ExecutionClass: FLEX
            GlueVersion: 4.0
            MaxRetries: 0
            NumberOfWorkers: 6
            Role: arn:aws:iam::467280971091:role/LabRole
            Timeout: 40
            WorkerType: G.1X
            Command:
                Name: glueetl
                ScriptLocation: s3://github-scrpits/Datawarehouse_Script.py

    
    GlueCrawler:
        Type: AWS::Glue::Crawler
        Properties:
            Name: CrawlingData64
            DatabaseName:  database64
            Targets:
                S3Targets:
                    - Path: s3://mergeddatar15/datawarehouse/
            Role: arn:aws:iam::467280971091:role/LabRole
    
    WorkflowLambda:
        Type: AWS::Lambda::Function
        Properties:
            Code:
                ZipFile: |
                    import json
                    import boto3
            
                    def lambda_handler(event, context):
                        glue = boto3.client('glue')
                        response = glue.start_workflow_run(Name='jobworkflow1')
                        print(response)
                        return {
                            'statusCode': 200,
                            'body': json.dumps('Hello from AWS Lambda!')
                        }
            
        Handler: index.lambda_handler
        Role: arn:aws:iam::467280971091:role/LabRole  # Different for everyone, change the ARN
        Runtime: python3.8
        FunctionName: 'LambdaforWorkflow'
            
    LambdaInvokePermission:
        Type: AWS::Lambda::Permission
        DependsOn: WorkflowLambda
        Properties:
            FunctionName: !GetAtt WorkflowLambda.Arn
            Action: lambda:InvokeFunction
            Principal: 's3.amazonaws.com'  # Corrected the principal
            SourceAccount: !Ref AWS::AccountId
            SourceArn: 'arn:aws:s3:::scriptfile1'  # Use GetAtt instead of Sub
  
    WorkflowStartTrigger:
          Type: AWS::Glue::Trigger
          Properties:
              Name: StartTrigger
              Type: ON_DEMAND
              Description: Trigger for starting the workflow
              Actions:
                - JobName: !Ref GlueJobImport
              WorkflowName:  !Ref WorkflowJob

    CrawlerJobTrigger:
        Type: AWS::Glue::Trigger
        Properties:
            Name: jobsuccesfultrigger1
            Type: CONDITIONAL
            StartOnCreation: TRUE
            Description: Trigger to start the crawler
            Actions:
              - CrawlerName :  CrawlingData64
            Predicate: 
              Conditions:
                - LogicalOperator: EQUALS
                  JobName: !Ref GlueJobImport
                  State: SUCCEEDED
            WorkflowName: !Ref WorkflowJob  
            
            
    MyAthenaWorkGroup:
        Type: AWS::Athena::WorkGroup
        Properties:
            Name: MyWorkGroup
            Description: workgroup for Athena
            State: ENABLED
            WorkGroupConfiguration:
                BytesScannedCutoffPerQuery: 200000000
                EnforceWorkGroupConfiguration: false
                PublishCloudWatchMetricsEnabled: true
                RequesterPaysEnabled: true
                ResultConfiguration:
                    OutputLocation: s3://finalbucketgrp4/    







                    